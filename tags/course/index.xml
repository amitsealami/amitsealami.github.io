<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Course on Amit Seal Ami</title>
    <link>https://amitsealami.github.io/tags/course/index.xml</link>
    <description>Recent content in Course on Amit Seal Ami</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; Amit Seal Ami</copyright>
    <atom:link href="/tags/course/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Tips and Tricks</title>
      <link>https://amitsealami.github.io/materials/applied_datascience/necessary_commands/</link>
      <pubDate>Thu, 22 Jun 2017 03:19:03 +0600</pubDate>
      
      <guid>https://amitsealami.github.io/materials/applied_datascience/necessary_commands/</guid>
      <description>

&lt;h4 id=&#34;any-generic-unix-commands&#34;&gt;Any Generic Unix Commands:&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;hadoop fs -&amp;lt;command&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;uploading-a-local-file&#34;&gt;Uploading a Local File&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;hadoop fs -put &amp;lt;filename&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;downloading-a-hadoop-file&#34;&gt;Downloading a Hadoop File&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;hadoop fs -get &amp;lt;filename&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;running-mapping-and-reducer&#34;&gt;Running Mapping and Reducer&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;hadoop jar /usr/lib/hadoop-0.20-mapreduce/contrib/streaming/hadoop-streaming-2.0.0-mr1-cdh4.1.1.jar -mapper &amp;lt;mapfile.py&amp;gt; -reducer &amp;lt;reducefile.py&amp;gt; -file &amp;lt;mapfile.py&amp;gt; -file &amp;lt;reducefile.py&amp;gt; -input &amp;lt;input_directory_in_hadoop&amp;gt; -output &amp;lt;output_directory_in_hadoop_must_not_exist_before&amp;gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Fortunately, Cloudera made an alias in the &lt;code&gt;~/.bashrc&lt;/code&gt; file which reduces the commands to  this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hs &amp;lt;mapper.py&amp;gt; &amp;lt;reducer.py&amp;gt; &amp;lt;input_directory&amp;gt; &amp;lt;output_directory&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Check out the file if you want to know how they intelligently created &lt;code&gt;shell function&lt;/code&gt; and &lt;code&gt;alias&lt;/code&gt; to reduce that huge command!&lt;/p&gt;

&lt;h3 id=&#34;dry-testing-without-running-hadoop&#34;&gt;Dry Testing without Running Hadoop&lt;/h3&gt;

&lt;p&gt;You probably already realized this, but hadoop runs like this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;run mapper -&amp;gt; sort output -&amp;gt; send output to reducer -&amp;gt; output&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Therefore, you can use the same mapper and reducer files in your local machine. For example, I do something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;python mapper.py &amp;lt; short_input_file.txt | sort &amp;gt; output.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you have guessed, I am using a short version of the actual input file to make things faster. If you are having trouble understanding what happened above, you need to understand a bit about Linux &lt;code&gt;Shell&lt;/code&gt; Commands, namely &lt;code&gt;Piping&lt;/code&gt; and &lt;code&gt;Filtering&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setting up Work Environment</title>
      <link>https://amitsealami.github.io/materials/applied_datascience/setting_up/</link>
      <pubDate>Thu, 22 Jun 2017 03:19:02 +0600</pubDate>
      
      <guid>https://amitsealami.github.io/materials/applied_datascience/setting_up/</guid>
      <description>&lt;p&gt;We will be using the Cloudera-Udacity Hadoop course materials.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Head over &lt;a href=&#34;https://www.udacity.com/course/intro-to-hadoop-and-mapreduce--ud617&#34;&gt;udacity&lt;/a&gt; if you have not registered already.&lt;/li&gt;
&lt;li&gt;Next, download the material from &lt;a href=&#34;https://docs.google.com/document/d/1v0zGBZ6EHap-Smsr3x3sGGpDW-54m82kDpPKC2M6uiY/edit&#34;&gt;here&lt;/a&gt; called  &lt;code&gt;Cloudera-Udacity-Training-VM-4.1.1.c.zip&lt;/code&gt;. It is around 2GB in size, so make sure you &lt;strong&gt;download it once&lt;/strong&gt; and then share it amongst other classmates.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Additionally, install &lt;a href=&#34;http://www.7-zip.org/download.html&#34;&gt;7zip&lt;/a&gt; if you do not have already in Windows. It is considerably faster for unzipping materials. If you are in Linux - you need to open terminal and type&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;unzip Cloudera-Udacity-Training-VM-4.1.1.c.zip -d udacity-cloudera
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;There are several files related to lightweight Hadoop setup from Cloudera in virtual disk image format. Even though it is possible to use VirtualBox to host the virtual image, &lt;a href=&#34;https://my.vmware.com/en/web/vmware/free#desktop_end_user_computing/vmware_workstation_player/12_0&#34;&gt;VMware&lt;/a&gt; is the preferred choice since it performs better.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If you are in Linux, you need to download the bundle file. When we downloaded it, it was &lt;code&gt;VMware-Player-12.5.7-5813279.x86_64.bundle&lt;/code&gt;. You need to execute the following from terminal:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chmod +x VMware-Player-12.5.7-5813279.x86_64.bundle
sudo ./VMware-Player-12.5.7-5813279.x86_64.bundle
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;pro tip: VMWare Player has some advanced options hidden at &lt;code&gt;/usr/lib/vmware/bin&lt;/code&gt;. For example, &lt;code&gt;vmware-netcfg&lt;/code&gt; helps you edit VMWare related network settings, which is not available in the regular user interface of VMWare Player.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When asked whether to install, install it.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Then, open VM Player. Click on Open a virtual machine, and select the vmx file from the extracted directory!

&lt;figure &gt;
    
        &lt;img src=&#34;../images/2017-06-22-13-02-52.png&#34; width=&#34;100%&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Opening the VMX file&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;
&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;If everything was done properly, something like this will show up:

&lt;figure &gt;
    
        &lt;img src=&#34;../images/2017-06-22-13-42-11.png&#34; width=&#34;100%&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;Hadoop is ready for Running!&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Congratulations! You have successfully completed the setting up of work environment. :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Applied Data Science</title>
      <link>https://amitsealami.github.io/materials/applied_datascience/</link>
      <pubDate>Thu, 22 Jun 2017 03:19:01 +0600</pubDate>
      
      <guid>https://amitsealami.github.io/materials/applied_datascience/</guid>
      <description>&lt;p&gt;Hello! This is the page for Applied Data Science Course offered at IIT, University of Dhaka. The contents are provided below:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;setting_up&#34;&gt;Getting Started - Setting up the environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;necessary_commands&#34;&gt;Tips and Tricks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
